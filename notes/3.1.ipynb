{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Снова возвращаемся к деревьям \n",
    "\n",
    "В этом уроке поговорим, почему наши деревья из второго модуля все еще переобучены! Да сколько можно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы подходим к завершению краткого введения в `data science`, машинное обучение. \n",
    "\n",
    "В этой неделе ещё немного поговорим про решающие деревья; про более продвинутые методы, которые получаются на их основе; затронем скорее в обзорном ключе направления, в которых можно двигаться дальше, если вам интересна эта тема и вы хотите развиваться в машинном обучении; поговорим про всякие интересные штуки; пообщаемся с приглашённым экспертом в нейросетях.\n",
    "\n",
    "Будет интересно и давайте продолжать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, второй модуль мы завершили на той ноте, что разобрались какую задачу решает модель машинного обучения, если мы решаем задачу классификации. Т.е. задача классификации понятна - классифицировать объект. Но вот как именно подойти к этому решению?\n",
    "\n",
    "Нам очевидно нужно натренировать наше дерево решений так, чтобы оно смогло на обучающих данных вычленить некоторую закономерность, которую можно было бы обобщить на те наблюдения, которые раньше оно не видело. И в данном случае нам поможет концепция тестового и обучающего множества, валидационного множества, кросс-валидации, подбора оптимального параметра и т.д.\n",
    "\n",
    "Я думаю, вы уже сразу заметили, что дерево решений в этом смысле как бы и хочет сделать как лучше, а получается, как всегда. \n",
    "\n",
    "Дерево решений - ужасно переобучаемый алгоритм. Всё, что в него заложено - вгрызаться в наши данные как можно глубже и на практике это приводит к тому, что, если дерево решений не контролировать, то единственное, что мы получим - переобученное дерево решений, которое очень сильно вычислит закономерности, зависящие от контекста обучающей выборки, а не общую закономерность, которую можно обобщить и на новые данные.\n",
    "\n",
    "Решением такой проблемы является подбор параметров нашего дерева, и мы разобрали один параметр - глубина, потому что он по сути самый серьезный для дерева решений. При прочих равных чем глубже дерево, тем оно более переобучено. НО! Бывают ситуации, когда глубокое дерево не является переобученным, т.е. просто в данной задаче нельзя обойтись деревом меньшей глубины.\n",
    "\n",
    "**Запомните: если при прочих равных мы можем добиться сходих метрик качества при меньшей глубине дерева, то лучше обойтись меньшей глубиной.**\n",
    "\n",
    "Однако даже после тюнинга глубины дерева можно заподозрить, что дерево всё ещё переобучено. на самом деле в каком-то смысле дерево решений всегда будет переобучено - такова природа этого алгоритма. \n",
    "\n",
    "Что можно заметить?\n",
    "\n",
    "У нас как минимум есть всего два наблюдения в одном из финальных прямоугольников. \n",
    "\n",
    "![](images/tree.png)\n",
    "\n",
    "И очевидно, что этот вот if, который разделит исходную более высокую выборку из 107 наблюдений на две части, в одной из которых окажется всего 2 элемента - кажется это довольно частая закономерность. И было бы здорово от этого избавиться. Возможно даже лучше нашему дереву решений будет, если мы заложим некоторое ограничение на то, какой размер выборки мы будем считать допустимым для того, чтобы ещё раз посплититься внутри этой выборки. И первое, что приходит на ум это ограничение глубины дерева. Например, задать глубину дерева 2. Но мы при этом потеряли бы важный третий слой глубины.\n",
    "\n",
    "Но у дерева есть не только глубина, но и другие важные параметры дерева решений. Например, `min_sample_split` - параметр показывающий допустимый размер выборки для дальнейшего сплита.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
